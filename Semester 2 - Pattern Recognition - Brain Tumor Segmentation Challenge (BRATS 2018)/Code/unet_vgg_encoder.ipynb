{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/vs-brats2018/miccai_brats_2018_data_training\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input/model-weight-tc/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #To remove folders\n# import os\n# import sys\n# import shutil\n\n# LABEL_PATH = \"../BraTs_Training_p508_npy/original/Label\"\n\n    \n# try:\n#     shutil.rmtree(LABEL_PATH)\n# except OSError as e:\n#     print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n    \n    \n    \n\n# DATA_PATH = \"../BraTs_Training_p508_npy/original/Data\"\n\n    \n# try:\n#     shutil.rmtree(DATA_PATH)\n# except OSError as e:\n#     print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n\n    \n\n\n    \n# try:\n#     shutil.rmtree(\"../BraTs_Training_p508_npy/\")\n# except OSError as e:\n#     print (\"Error: %s - %s.\" % (e.filename, e.strerror))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport nibabel as nib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\n\nIMG_WIDTH = 240\nIMG_HEIGHT = 240\nIMG_CHANNELS = 4\nHW = 100\nTRAIN_PATH = \"../input/vs-brats2018/miccai_brats_2018_data_training\"\nSTORE_PATH = \"../BraTs_Training_p508_npy/original/Data\"\nLABEL_PATH = \"../BraTs_Training_p508_npy/original/Label\"\n\n\nimport matplotlib.image as mpimg\nfrom scipy.stats import skew\nfrom scipy.stats import kurtosis\nimport numpy.ma as ma\n\ndirs_all = os.listdir(TRAIN_PATH)\ndirs_all.sort()\ndirs_train = dirs_all[:2]\ntraining_data = []\nlabel_data = []\n\n\ndef normalize_image(im):\n  im_mask = (im > 0);\n  im_compressed_region = ma.array(im,mask=~im_mask).compressed()\n  #print(im_compressed_region.size)\n  \n  #plt.imshow(im_mask)\n  #plt.show()\n  #plt.imshow(im)\n  #plt.show()\n  if (im_compressed_region.size == 0):\n    return im\n  else:\n    avg = np.mean(im_compressed_region,dtype='float32')\n    std = np.std(im_compressed_region,dtype='float32')\n    return (ma.array(im,mask=~im_mask)-avg)/std\n\naxial_data_path = [];\naxial_label_path = [];\n\nsagittal_data_path = [];\nsagittal_label_path = [];\n\ncoronal_data_path = [];\ncoronal_label_path = [];\nfor nf, folder in enumerate(dirs_train):\n  print(\"Processing Images...\")\n  HLG_PATH = os.path.join(TRAIN_PATH,folder)\n  hlg_all = os.listdir(HLG_PATH)  \n  if nf == 0:\n    hlg_all.remove('Brats18_2013_22_1')\n    hlg_all.remove('Brats18_CBICA_ABN_1')\n    hlg_all.remove('Brats18_TCIA01_201_1')\n    hlg_all.remove('Brats18_TCIA08_406_1')\n    hlg_all.remove('Brats18_CBICA_ARZ_1')\n    hlg_all.remove('Brats18_TCIA01_131_1')\n    hlg_all.remove('Brats18_2013_7_1')\n  else:\n    hlg_all.remove('Brats18_2013_0_1')\n    hlg_all.remove('Brats18_2013_6_1')\n    hlg_all.remove('Brats18_TCIA10_266_1')  \n  np.random.shuffle(hlg_all)\n  for n, file in enumerate(hlg_all):\n    print(\"Image: \"+ str(nf) + \", \" + str(n))\n    flair = nib.load(os.path.join(HLG_PATH, file, file + '_flair.nii.gz')).get_data()\n    t1 = nib.load(os.path.join(HLG_PATH, file, file + '_t1.nii.gz')).get_data()\n    t1ce = nib.load(os.path.join(HLG_PATH, file, file + '_t1ce.nii.gz')).get_data()\n    t2 = nib.load(os.path.join(HLG_PATH, file, file + '_t2.nii.gz')).get_data()\n    label = nib.load(os.path.join(HLG_PATH, file, file + '_seg.nii.gz')).get_data()\n    \n    #label_patch = np.zeros([240,240,4],dtype='int')\n    print(\"Axial Data:\")    \n    folder_directory = os.path.join(STORE_PATH,folder,file,'axial','ori')\n    if not os.path.exists(folder_directory):\n      os.makedirs(folder_directory)\n      for i in range(155):\n        if(np.mean(flair[:,:,i]+t1[:,:,i]+t1ce[:,:,i]+t2[:,:,i])!=0):\n            data_patch_axial = np.zeros([240,240,4],dtype='float32')\n\n            data_patch_axial[:,:,0] = normalize_image(flair[:,:,i])\n            data_patch_axial[:,:,1] = normalize_image(t1[:,:,i])\n            data_patch_axial[:,:,2] = normalize_image(t1ce[:,:,i])\n            data_patch_axial[:,:,3] = normalize_image(t2[:,:,i])\n\n            np.save(os.path.join(folder_directory,'pao'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'),data_patch_axial)\n            axial_data_path.append(os.path.join(folder_directory,'pao'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'));      \n\n    print(\"Axial Label:\")\n    folder_directory = os.path.join(LABEL_PATH,folder,file,'axial','ori')\n    if not os.path.exists(folder_directory):\n      os.makedirs(folder_directory)\n\n      for i in range(155):\n        if(np.mean(flair[:,:,i]+t1[:,:,i]+t1ce[:,:,i]+t2[:,:,i])!=0):        \n            label_patch_axial = np.zeros([240,240,1],dtype='float32')\n\n            label_patch_axial[:,:,0] = (label[:,:,i]>0.0)*1.0 #WT\n            #label_patch_axial[:,:,0] = (label[:,:,i]==1.0) * 1.0 + (label[:,:,i]==4.0)*1.0 #TC\n            #label_patch_axial[:,:,0] = (label[:,:,i]==4.0)*1.0 #ET\n\n            np.save(os.path.join(folder_directory,'pao'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'),label_patch_axial)\n            axial_label_path.append(os.path.join(folder_directory,'pao'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'));\n\n\"\"\"\n    ##############################################################################################################################################################################################\n    \n    print(\"Sagittal Data:\")\n    folder_directory = os.path.join(STORE_PATH,folder,file,'sagittal')\n    if not os.path.exists(folder_directory):\n      os.makedirs(folder_directory)\n      for i in range(240):\n\n        data_patch_sagittal = np.zeros([240,240,4],dtype='float32')\n\n        data_patch_sagittal[:,41:196,0] = normalize_image(flair[i,:,:])\n        data_patch_sagittal[:,41:196,1] = normalize_image(t1[i,:,:])\n        data_patch_sagittal[:,41:196,2] = normalize_image(t1ce[i,:,:])\n        data_patch_sagittal[:,41:196,3] = normalize_image(t2[i,:,:])\n\n\n        np.save(os.path.join(folder_directory,'pso'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'),data_patch_sagittal)\n        sagittal_data_path.append(os.path.join(folder_directory,'pso'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'));\n    \n    print(\"Sagittal Label:\")\n    folder_directory = os.path.join(LABEL_PATH,folder,file,'sagittal')\n    if not os.path.exists(folder_directory):\n      os.makedirs(folder_directory)\n      for i in range(240):\n\n        label_patch_sagittal = np.zeros([240,240,1],dtype='int')\n\n        label_patch_sagittal[:,41:196,0] = (label[i,:,:]>0).astype(int)\n\n        np.save(os.path.join(folder_directory,'pso'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'),label_patch_sagittal)\n        sagittal_label_path.append(os.path.join(folder_directory,'pso'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'));\n\n    ###############################################################################\n    print(\"Coronal Data:\")\n    folder_directory = os.path.join(STORE_PATH,folder,file,'coronal')\n    if not os.path.exists(folder_directory):\n      os.makedirs(folder_directory)\n      for i in range(240):\n\n        data_patch_coronal = np.zeros([240,240,4],dtype='float32')\n\n        data_patch_coronal[:,41:196,0] = normalize_image(flair[:,i,:])\n        data_patch_coronal[:,41:196,1] = normalize_image(t1[:,i,:])\n        data_patch_coronal[:,41:196,2] = normalize_image(t1ce[:,i,:])\n        data_patch_coronal[:,41:196,3] = normalize_image(t2[:,i,:])\n        \n        np.save(os.path.join(folder_directory,'pco'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'),data_patch_coronal)\n        coronal_data_path.append(os.path.join(folder_directory,'pco'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'));\n          \n    print(\"Coronal Label:\")          \n    folder_directory = os.path.join(LABEL_PATH,folder,file,'coronal')\n    if not os.path.exists(folder_directory):\n      os.makedirs(folder_directory)\n      for i in range(240):\n        \n        label_patch_coronal = np.zeros([240,240,1],dtype='int')\n        \n        label_patch_coronal[:,41:196,0] = (label[:,i,:]>0).astype(int)\n        \n        np.save(os.path.join(folder_directory,'pco'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'),label_patch_coronal)\n        coronal_label_path.append(os.path.join(folder_directory,'pco'+ '_' + str(nf) + '_' + str(n) + '_' + str(i) + '.npy'));\n\"\"\"   \nnp.save(os.path.join('../BraTs_Training_p508_npy/axial_data_path'+ '.npy'),axial_data_path)    \nnp.save(os.path.join('../BraTs_Training_p508_npy/axial_label_path'+ '.npy'),axial_label_path)\n#np.save(os.path.join('/content/drive/My Drive/Colab Notebooks/BraTs_Training_p508_npy/sagittal_data_path'+ '.npy'),sagittal_data_path)    \n#np.save(os.path.join('/content/drive/My Drive/Colab Notebooks/BraTs_Training_p508_npy/sagittal_label_path'+ '.npy'),sagittal_label_path)\n#np.save(os.path.join('/content/drive/My Drive/Colab Notebooks/BraTs_Training_p508_npy/coronal_data_path'+ '.npy'),coronal_data_path)    \n#np.save(os.path.join('/content/drive/My Drive/Colab Notebooks/BraTs_Training_p508_npy/coronal_label_path'+ '.npy'),coronal_label_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir('/kaggle/config')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# import numpy as np\n# dirs_data = np.load('../BraTs_Training_p508_npy/axial_data_path'+ '.npy')\n# dirs_label = np.load('../BraTs_Training_p508_npy/axial_label_path'+ '.npy')\n# print(dirs_data)\n# print(dirs_label)\n# print(dirs_data.shape)\n# print(dirs_data.size)\n# for i in range(dirs_data.size):\n#   print(i)\n#   #print(dirs_data[i,])\n#   dummy_data = np.load(dirs_data[i,])\n#   print(dummy_data.shape)\n#   dummy_label = np.load(dirs_label[i,])\n#   print(dummy_label.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\n\ndirs_all = os.listdir(TRAIN_PATH)\ndirs_all.sort()\ndirs_train = dirs_all[:2]\ntraining_data = []\nlabel_data = []\n\n\nimport keras\nimport os\nimport sys\nimport nibabel as nib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\nfrom keras.optimizers import Adam, SGD\nfrom keras import backend as K\n\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels, batch_size=32, dim=(240,240,4),dim_lab=(240,240,1), n_channels=4,\n                 n_classes=2, shuffle=False):\n        'Initialization'\n        self.dim = dim\n        self.dim_lab = dim_lab        \n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        #self.image_size = image_size #Thats new\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        #print(indexes)\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim))\n        y = np.empty((self.batch_size, *self.dim_lab))\n        #print(X.shape)\n        #print(y.shape)\n        # Generate data\n        \n        \n        \n        #dirs_data = np.load('/content/drive/My Drive/BraTs_Training_p508_npy/axial_data_path'+ '.npy')\n        dirs_data = np.load('../BraTs_Training_p508_npy/axial_data_path'+ '.npy')\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            #X[i,] = np.load(STORE_PATH + \"/\" + ID)\n            #print(ID)\n            X[i,] = np.load(ID)\n            LABEL_ID=ID.replace(\"Data\", \"Label\")\n            # Store class\n            #y[i,] = np.load(LABEL_PATH + \"/\" + ID)\n            y[i,] = np.load(LABEL_ID)\n\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(STORE_PATH)\n\ndirs_all = np.load('../BraTs_Training_p508_npy/axial_data_path'+ '.npy')\n#dirs_data = np.load('/content/drive/My Drive/Colab Notebooks/BraTs_Training_p508_npy/axial_data_path'+ '.npy')\n#dirs_label = np.load('/content/drive/My Drive/Colab Notebooks/BraTs_Training_p508_npy/axial_label_path'+ '.npy')\n#dirs_all = [];\n#dirs_all = np.array([dirs_data],[dirs_label])\n#print(dirs_all.shape)\n\n\n#dirs_all.sort()\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#print(dirs_all)\n\n# Parameters\nparams = {'dim': (240,240,4),\n          'dim_lab': (240,240,1),\n          'batch_size': 16,\n          'n_classes': 2,\n          'n_channels': 4,\n          'shuffle': False}\n\n# split_len = int(len(dirs_all) * 0.8)\n# train = dirs_all[1:split_len]\n# validation = dirs_all[split_len:]\n# np.random.shuffle(train)\n# np.random.shuffle(validation)\n\nnp.random.shuffle(dirs_all)\nsplit_len = int(len(dirs_all) * 0.8)\ntrain = dirs_all[1:split_len]\nvalidation = dirs_all[split_len:]\n\n# Generators\ntraining_generator = DataGenerator(train, train, **params)\n\n#print(training_generator)\nvalidation_generator = DataGenerator(validation, validation, **params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if(True):\n    x,y = training_generator.__getitem__(1);\n\n    print(x.shape)\n    print(y.shape)    \n    for num in range(16):\n        plt.figure(figsize=(15,8))\n        plt.subplot(2, 4, 1)\n        plt.imshow(x[num,:,:,0],cmap='gray') # BGR->RGB for plotting\n        plt.subplot(2, 4, 2)\n        plt.imshow(x[num,:,:,1],cmap='gray') # BGR->RGB for plotting\n        plt.subplot(2, 4, 3)\n        plt.imshow(x[num,:,:,2],cmap='gray') # BGR->RGB for plotting\n        plt.subplot(2, 4, 4)\n        plt.imshow(x[num,:,:,3],cmap='gray') # BGR->RGB for plotting\n        plt.subplot(2, 4, 5)\n        plt.imshow(y[num,:,:,0],cmap='gray') # BGR->RGB for plotting\n        plt.subplot(2, 4, 6)\n        plt.imshow(y[num,:,:,0],cmap='gray') # BGR->RGB for plotting\n        plt.subplot(2, 4, 7)\n        plt.imshow(y[num,:,:,0],cmap='gray') # BGR->RGB for plotting\n        plt.subplot(2, 4, 8)\n        plt.imshow(y[num,:,:,0],cmap='gray') # BGR->RGB for plotting\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\nfrom keras.regularizers import l2\nfrom keras.applications.vgg16 import VGG16\n\nIMG_WIDTH = 240\nIMG_HEIGHT = 240\nIMG_CHANNELS = 4\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n     \nweight_decay=0.0\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))   \n\n#Encoder\n# Block 1\nconv1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1_1', kernel_initializer=initializers.random_normal(stddev=0.01))(inputs)\nconv1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', kernel_initializer=initializers.random_normal(stddev=0.01))(conv1)\npool1 = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(conv1)\n\n# Block 2\nconv2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', kernel_initializer=initializers.random_normal(stddev=0.01))(pool1)\nconv2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', kernel_initializer=initializers.random_normal(stddev=0.01))(conv2)\npool2 = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(conv2)\n\n# Block 3\nconv3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', kernel_initializer=initializers.random_normal(stddev=0.01))(pool2)\nconv3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', kernel_initializer=initializers.random_normal(stddev=0.01))(conv3)\nconv3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', kernel_initializer=initializers.random_normal(stddev=0.01))(conv3)\npool3 = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(conv3)\n\n# Block 4\nconv4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', kernel_initializer=initializers.random_normal(stddev=0.01))(pool3)\nconv4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', kernel_initializer=initializers.random_normal(stddev=0.01))(conv4)\nconv4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', kernel_initializer=initializers.random_normal(stddev=0.01))(conv4)\npool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(conv4)\n\n# Block 5\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', kernel_initializer=initializers.random_normal(stddev=0.01))(pool4)\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', kernel_initializer=initializers.random_normal(stddev=0.01))(conv5)\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', kernel_initializer=initializers.random_normal(stddev=0.01))(conv5)\npool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(conv5)\n\n#Bottleneck\nconv_b = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer=initializers.random_normal(stddev=0.01))(pool5)\nconv_b = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv_b)\n# drop5 = Dropout(0.5)(conv_b)\n\n#Decoder\ndeconv_6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv_b)\nzero_conv6 = ZeroPadding2D(padding=((1,0),(1,0)))(deconv_6)\nup6 = concatenate([zero_conv6, conv5], axis=3)\nconv6 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(up6)\nconv6 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv6)\nconv6 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv6)\n\nup7 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv6), conv4], axis=3)\nconv7 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(up7)\nconv7 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv7)\nconv7 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv7)\n\nup8 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv7), conv3], axis=3)\nconv8 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(up8)\nconv8 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv8)\nconv8 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv8)\n\nup9 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv8), conv2], axis=3)\nconv9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(up9)\nconv9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv9)\n\nup10 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv9), conv1], axis=3)\nconv10 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(up10)\nconv10 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer=initializers.random_normal(stddev=0.01))(conv10)\n\n#Output layer\nconv11 = Conv2D(1, (1, 1), activation='sigmoid')(conv10)\n\nmodel = Model(inputs=[inputs], outputs=[conv11])\n\nweights_path = '/kaggle/input/modelweights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel.load_weights(weights_path, by_name=True)\n\n# model.summary()\nmodel.compile(optimizer=Adam(lr=1e-4), loss=dice_coef_loss, metrics=[dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from keras import backend as K\n#print(K.image_data_format())\n#model = UNet()\n\n\n#model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\ncsv_logger = CSVLogger('training_vgg_WT.csv')\nearlystopper = EarlyStopping(patience=20, verbose=1)\ncheckpointer = ModelCheckpoint('model_BRATS_VGG_WT.h5', verbose=1, save_best_only=True)\nlr_callback = ReduceLROnPlateau(monitor='val_dice_coef', patience=3, verbose=1, factor=0.5, min_lr=1e-4)\nresults = model.fit_generator(generator=training_generator,validation_data=validation_generator, epochs=30, \n                    callbacks=[earlystopper, checkpointer, tensorboard, csv_logger])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Display Result\n# trained_model = load_model('/kaggle/Model/model_BRATS_VGG_TC.h5', custom_objects={'dice_coef_loss':\n# dice_coef_loss,'dice_coef':                   \n# dice_coef})\n\n# for j in range(4):\n#   x,y = validation_generator.__getitem__(j);\n#   test_data = x[:,:,:,:]\n#   pred_value = trained_model.predict(test_data, verbose = 1)\n#   acc = 0\n#   nn = 0\n#   total_acc = 0\n#   for i in range(32):    \n#     # Some tensor we want to print the value of\n#   #   a = dice_coef(y[i,:,:,:],pred_value[i,:,:,:])\n\n#   #   # Add print operation\n#   #   a = tf.Print(a, [a], message=\"This is a: \") \n#     test = np.expand_dims(x[i,:,:,:],axis=0)\n#     print(test.shape)\n#     test_l = np.expand_dims(y[i,:,:,:],axis=0)\n#     score = trained_model.evaluate(test, test_l, batch_size = 1)  \n#     total_acc += score[1] \n#     if (score[1]<0.99):\n#       acc += score[1]\n#       nn += 1\n#     print('Score:'+str(score))\n#     plt.subplot(1,3,1)\n#     plt.imshow(x[i,:,:,0], cmap = 'gray')\n#     plt.subplot(1,3,2)\n#     plt.imshow(pred_value[i,:,:,0], cmap = 'gray')\n#     plt.subplot(1,3,3)\n#     plt.imshow(y[i,:,:,0], cmap = 'gray')\n#     plt.show()\n#   print('i:'+str(j)+' :'+str(acc/nn))  \n#   print('i:'+str(j)+' :'+str(total_acc/16)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.image as mpimg\n# from scipy.stats import skew\n# from scipy.stats import kurtosis\n# import numpy.ma as ma\n# from keras.models import *\n# from keras.layers import *\n# from keras.optimizers import *\n# from keras import backend as K\n# from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n# from keras.regularizers import l2\n# from keras.applications.vgg16 import VGG16\n# from scipy import ndimage\n# import keras\n# import os\n# import sys\n# import nibabel as nib\n# import numpy as np\n# import matplotlib.pyplot as plt\n\n# def dice_coef(y_true, y_pred, smooth=1):\n#     y_true_f = K.flatten(y_true)\n#     y_pred_f = K.flatten(y_pred)\n#     intersection = K.sum(y_true_f * y_pred_f)\n#     return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# def dice_coef_loss(y_true, y_pred):\n#     return 1 - dice_coef(y_true, y_pred)\n# def normalize_image(im):\n#   im_mask = (im > 0);\n#   im_compressed_region = ma.array(im,mask=~im_mask).compressed()\n#   #print(im_compressed_region.size)\n  \n#   #plt.imshow(im_mask)\n#   #plt.show()\n#   #plt.imshow(im)\n#   #plt.show()\n#   if (im_compressed_region.size == 0):\n#     return im\n#   else:\n#     avg = np.mean(im_compressed_region,dtype='float32')\n#     std = np.std(im_compressed_region,dtype='float32')\n#     return (ma.array(im,mask=~im_mask)-avg)/std\n# TRAIN_PATH = \"../input/vs-brats2018/miccai_brats_2018_data_training\"\n# dirs_all = os.listdir(TRAIN_PATH)\n# dirs_all.sort()\n# dirs_train = dirs_all[:2]\n# trained_model = load_model('/kaggle/input/model-weight-tc/model_BRATS_VGG_WT.h5', custom_objects={'dice_coef_loss': dice_coef_loss,'dice_coef': dice_coef})\n\n# test_patients = ['Brats18_2013_22_1','Brats18_CBICA_ABN_1','Brats18_TCIA01_201_1','Brats18_TCIA08_406_1'\n#                 ,'Brats18_CBICA_ARZ_1','Brats18_TCIA01_131_1','Brats18_2013_7_1','Brats18_2013_0_1'\n#                 ,'Brats18_2013_6_1','Brats18_TCIA10_266_1']\n# count = 0\n# dice_test = 0\n# for nf, folder in enumerate(dirs_train):\n#   print(\"Processing Images...\")\n#   HLG_PATH = os.path.join(TRAIN_PATH,folder)\n#   hlg_all = os.listdir(HLG_PATH)  \n\n#   for n, file in enumerate(hlg_all):\n#     if file in test_patients:\n#         count = count + 1\n#         print(file)\n#         print(\"Image: \"+ str(nf) + \", \" + str(n))\n#         flair = nib.load(os.path.join(HLG_PATH, file, file + '_flair.nii.gz')).get_data()\n#         t1 = nib.load(os.path.join(HLG_PATH, file, file + '_t1.nii.gz')).get_data()\n#         t1ce = nib.load(os.path.join(HLG_PATH, file, file + '_t1ce.nii.gz')).get_data()\n#         t2 = nib.load(os.path.join(HLG_PATH, file, file + '_t2.nii.gz')).get_data()\n#         label = nib.load(os.path.join(HLG_PATH, file, file + '_seg.nii.gz')).get_data()\n\n#         print(\"Axial Data:\")    \n#         axial = 0;\n#         for i in range(155):\n#             if(np.mean(flair[:,:,i]+t1[:,:,i]+t1ce[:,:,i]+t2[:,:,i])!=0):\n#                 data_patch_axial = np.zeros([240,240,4],dtype='float32')\n#                 data_patch_axial[:,:,0] = normalize_image(flair[:,:,i])\n#                 data_patch_axial[:,:,1] = normalize_image(t1[:,:,i])\n#                 data_patch_axial[:,:,2] = normalize_image(t1ce[:,:,i])\n#                 data_patch_axial[:,:,3] = normalize_image(t2[:,:,i])\n#                 if (axial == 0):\n#                     data_patch_axial_test = np.expand_dims(data_patch_axial,axis=0)\n#                 else:\n#                     data_patch_axial = np.expand_dims(data_patch_axial,axis=0)\n#                     data_patch_axial_test = np.concatenate((data_patch_axial_test,data_patch_axial),axis = 0)\n#                 axial = axial + 1\n                \n#         axial = 0\n#         for i in range(155):\n#             if(np.mean(flair[:,:,i]+t1[:,:,i]+t1ce[:,:,i]+t2[:,:,i])!=0):\n#                 label_patch_axial = np.zeros([240,240,1],dtype='float32')\n                \n                \n#                 label_patch_axial[:,:,0] = (label[:,:,i]>0.0)*1.0 #WT\n#                 #label_patch_axial[:,:,0] = (label[:,:,i]==1.0) * 1.0 + (label[:,:,i]==4.0)*1.0 #TC\n#                 #label_patch_axial[:,:,0] = (label[:,:,i]==4.0)*1.0 #ET\n# #                 label_patch_axial[:,:,0] = (label[:,:,i]>0.0).astype(int) #WT\n# #                 label_patch_axial[:,:,1] = (label[:,:,i]==1).astype(int)\n# #                 label_patch_axial[:,:,2] = (label[:,:,i]==2).astype(int)\n# #                 label_patch_axial[:,:,3] = (label[:,:,i]==4).astype(int)\n#                 if (axial == 0):\n#                     label_patch_axial_test = np.expand_dims(label_patch_axial,axis=0)\n#                 else:\n#                     label_patch_axial = np.expand_dims(label_patch_axial,axis=0)\n#                     label_patch_axial_test=np.concatenate((label_patch_axial_test,label_patch_axial),axis = 0)\n#                 axial = axial + 1\n         \n#         print(label_patch_axial_test.shape[0])\n#         print(data_patch_axial_test.shape)\n#         pred_value = trained_model.predict(data_patch_axial_test, verbose = 1)\n#         evaluation = trained_model.evaluate(x=data_patch_axial_test, y=label_patch_axial_test,batch_size = label_patch_axial_test.shape[0])\n#         plt.figure(figsize=(8,8)) \n#         plt.imshow(data_patch_axial_test[100,:,:,0], cmap = 'gray')\n#         plt.title(\"Flair\")\n#         plt.show()\n#         plt.figure(figsize=(8,8)) \n#         plt.imshow(data_patch_axial_test[100,:,:,1], cmap = 'gray')\n#         plt.title(\"T1\")\n#         plt.show()\n#         plt.figure(figsize=(8,8)) \n#         plt.imshow(data_patch_axial_test[100,:,:,2], cmap = 'gray')\n#         plt.title(\"T1ce\")\n#         plt.show()\n#         plt.figure(figsize=(8,8)) \n#         plt.imshow(data_patch_axial_test[100,:,:,3], cmap = 'gray')\n#         plt.title(\"T2\")\n#         plt.show()\n#         plt.figure(figsize=(8,8)) \n#         plt.imshow(pred_value[100,:,:,0], cmap = 'gray')\n#         plt.title(\"Predicted\")\n#         plt.show()\n#         plt.figure(figsize=(8,8)) \n#         plt.imshow(label_patch_axial_test[100,:,:,0], cmap = 'gray')\n#         plt.title(\"Ground Truth\")\n#         plt.show()\n#         print(evaluation)\n#         dice_test = np.asarray(evaluation) +dice_test\n\n# print(\"test accuracy:\")\n# print(dice_test/count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}